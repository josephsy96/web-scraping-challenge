{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mission to Mars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Website to scrape\n",
    "\n",
    "mission_url = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'\n",
    "mission_html = requests.get(mission_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BS module\n",
    "mission_soup = bs(mission_html.text,'html.parser')\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable to iterate through the website\n",
    "mars_t = mission_soup.find_all('div', {'class':'content_title'})\n",
    "mars_p = mission_soup.find_all('div', {'class':'rollover_description'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "para = []\n",
    "\n",
    "#Append data into lists\n",
    "for mt in mars_t:\n",
    "    \n",
    "    mars_title = mt.find('a').text\n",
    "    title.append(mars_title)\n",
    "\n",
    "for mp in mars_p:\n",
    "    mars_para = mp.find('div',{'class':'rollover_description_inner'}).text\n",
    "    para.append(mars_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print article titles\n",
    "for t in title:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print article contents\n",
    "for p in para:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPL Photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Browser elements\n",
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL Info\n",
    "splinter_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(splinter_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup pull points\n",
    "splinter_html = browser.html\n",
    "\n",
    "splinter_soup = bs(splinter_html, 'html.parser')\n",
    "jpl_url = []\n",
    "\n",
    "art = splinter_soup.select_one('article[class=\"carousel_item\"]')\n",
    "\n",
    "#Grab url\n",
    "featured_image_url = art['style'].split(\"url('\")[1][:-3]\n",
    "jpl_url.append(splinter_url + featured_image_url)\n",
    "print(jpl_url[0])\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mars Twitter Page\n",
    "url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "\n",
    "html = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soup module\n",
    "soup = bs(html.text,'html.parser')\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find list items\n",
    "mars_tweets = soup.find_all(\"li\", class_=\"js-stream-item\")\n",
    "mars_weather = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a conditional statement to only pull account tweet instead of retweets.\n",
    "\n",
    "for tweets in mars_tweets:\n",
    "    rt = tweets.find('p',class_='tweet-text').text.strip().split('pic*')[0][:-26]\n",
    "    \n",
    "    mars_weather.append(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mars_weather[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conditional to only pull weather tweets\n",
    "only_weather = [m for m in mars_weather if \"InSight\" in m]\n",
    "fwt = only_weather[0]\n",
    "print(fwt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Master Lists\n",
    "title_list = []\n",
    "url_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cerberus Hemi \n",
    "c_url = \"https://astrogeology.usgs.gov/search/map/Mars/Viking/cerberus_enhanced\"\n",
    "\n",
    "c_html = requests.get(c_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hemi BeautifulSoup\n",
    "c_soup = bs(c_html.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull title and image\n",
    "cerb_site = c_soup.find_all('div',{'class':'container'})\n",
    "\n",
    "# cerb_list = []\n",
    "# cerb_image = []\n",
    "\n",
    "for ct in cerb_site:\n",
    "    cerb_img_url = ct.find('img',{'class':'wide-image'})['src']\n",
    "    cerb_title = ct.find('h2',{'class':'title'})\n",
    "    \n",
    "    title_list.append(cerb_title.text)\n",
    "    url_list.append(c_url + cerb_img_url)\n",
    "\n",
    "# print(cerb_list[0])\n",
    "# print(cerb_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schiaparelli URL\n",
    "s_url = \"https://astrogeology.usgs.gov/search/map/Mars/Viking/schiaparelli_enhanced\"\n",
    "\n",
    "s_html = requests.get(s_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull title and image\n",
    "schi_site = s_soup.find_all('div',{'class':'container'})\n",
    "\n",
    "# schi_list = []\n",
    "# schi_image = []\n",
    "\n",
    "for st in schi_site:\n",
    "    schi_image_url = st.find('img',{'class':'wide-image'})['src']\n",
    "    schi_title = st.find('h2',{'class':'title'})\n",
    "    \n",
    "    url_list.append(s_url + schi_image_url)\n",
    "    title_list.append(schi_title.text)\n",
    "    \n",
    "# print(schi_list[0])\n",
    "# print(schi_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syrtis URL\n",
    "sy_url = \"https://astrogeology.usgs.gov/search/map/Mars/Viking/syrtis_major_enhanced\"\n",
    "\n",
    "sy_html = requests.get(sy_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syrtis BeautifulSoup\n",
    "sy_soup = bs(sy_html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull title and image\n",
    "sy_site = sy_soup.find_all('div',{'class':'container'})\n",
    "\n",
    "# sy_list = []\n",
    "# sy_image = []\n",
    "\n",
    "for syt in sy_site:\n",
    "    sy_img_url = syt.find('img',{'class':'wide-image'})['src']\n",
    "    sy_title = syt.find('h2',{'class':'title'}).text\n",
    "    \n",
    "    title_list.append(sy_title)\n",
    "    url_list.append(sy_url + sy_img_url)\n",
    "    \n",
    "# print(sy_list[0])\n",
    "# print(sy_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valles URL\n",
    "v_url = \"https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced\"\n",
    "\n",
    "v_html = requests.get(v_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valles BeautifulSoup\n",
    "v_soup = bs(v_html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_site = v_soup.find_all('div', {'class':'container'})\n",
    "\n",
    "# v_list = []\n",
    "# v_image = []\n",
    "\n",
    "for vt in v_site:\n",
    "    v_img_url = vt.find('img', {'class':'wide-image'})['src']\n",
    "    v_title = vt.find('h2',{'class':'title'}).text\n",
    "    \n",
    "    url_list.append(v_url + v_img_url)\n",
    "    title_list.append(v_title)\n",
    "    \n",
    "# print(v_list[0])\n",
    "# print(v_image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dictionary\n",
    "hemi_dict = {'title': title_list,'hemisphere': url_list}\n",
    "\n",
    "#Print test\n",
    "print(hemi_dict['hemisphere'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mars Facts website\n",
    "facts_url = \"https://space-facts.com/mars/\"\n",
    "\n",
    "#Munge Data\n",
    "mars_facts = pd.read_html(facts_url)\n",
    "mars_df = mars_facts[0]\n",
    "mars_df.columns = ['Mars','Info']\n",
    "mars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set mars_df to html\n",
    "mars_html = mars_df.to_html()\n",
    "mars_html.replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_df.to_html('mars_table.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
